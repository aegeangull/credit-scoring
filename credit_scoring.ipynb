{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lofo-importance\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", None)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "import shap\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/kaggle/input/home-credit-default-risk/\"\n",
    "\n",
    "# Define a list of filenames\n",
    "filenames = [\n",
    "    \"application_train.csv\",\n",
    "    \"application_test.csv\",\n",
    "    \"POS_CASH_balance.csv\",\n",
    "    \"bureau.csv\",\n",
    "    \"bureau_balance.csv\",\n",
    "    \"previous_application.csv\",\n",
    "    \"credit_card_balance.csv\",\n",
    "    \"installments_payments.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    df_var = f\"{filename[:-4]}_df\"  \n",
    "    dataframes[df_var] = pd.read_csv(f\"{base_path}{filename}\")\n",
    "\n",
    "\n",
    "train_df = dataframes[\"application_train_df\"]\n",
    "test_df = dataframes[\"application_test_df\"]\n",
    "bureau_df = dataframes[\"bureau_df\"]\n",
    "bureau_balance_df = dataframes[\"bureau_balance_df\"]\n",
    "previous_application_df = dataframes[\"previous_application_df\"]\n",
    "pos_cash_balance_df = dataframes[\"POS_CASH_balance_df\"]\n",
    "credit_card_balance_df = dataframes[\"credit_card_balance_df\"]\n",
    "installments_payments_df = dataframes[\"installments_payments_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = pd.read_csv('/kaggle/input/home-credit-default-risk/HomeCredit_columns_description.csv',encoding='ISO-8859-1')\n",
    "pd.set_option('display.max_columns', None)\n",
    "description_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_cat = train_df.select_dtypes(include=[\"object\"]).columns\n",
    "train_df_num = [x for x in train_df if x not in train_df_cat] \n",
    "\n",
    "print(f'Train data shape: {train_df.shape}')\n",
    "print(train_df.info())\n",
    "print(f'\\nCategoric features count: {len(train_df_cat)}')\n",
    "print(f'Numeric features count: {len(train_df_num)}')\n",
    "\n",
    "print('\\nTrain Samples')\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get more statistical information about Train data\n",
    "desc = pd.DataFrame(index=list(train_df))\n",
    "desc['type'] = train_df.dtypes\n",
    "desc['count'] = train_df.count()\n",
    "desc['nunique'] = train_df.nunique()\n",
    "desc['%unique'] = desc['nunique'] / len(train_df) * 100\n",
    "desc['null'] = train_df.isnull().sum()\n",
    "desc['%null'] = desc['null'] / len(train_df) * 100\n",
    "desc = pd.concat([desc, train_df.describe().T.drop('count', axis=1)], axis=1)\n",
    "desc.sort_values(by=['type', 'null']).style.background_gradient(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_cat = test_df.select_dtypes(include=[\"object\"]).columns\n",
    "test_df_num = [x for x in test_df if x not in test_df_cat] \n",
    "\n",
    "print(f'Test data shape: {test_df.shape}')\n",
    "print(test_df.info())\n",
    "print(f'\\nCategoric features count: {len(test_df_cat)}')\n",
    "print(f'Numeric features count: {len(test_df_num)}')\n",
    "\n",
    "print('\\nTest Samples')\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function drawn by the information of extra data\n",
    "def load_data(path, name):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"{name}: shape is {df.shape}\")\n",
    "    print(df.info())\n",
    "    \n",
    "    cat_features = df.select_dtypes(include=['object']).columns\n",
    "    num_features = df.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "    print(f'\\nCategoric features count: {len(cat_features)}')\n",
    "    print(f'Numeric features count: {len(num_features)}')\n",
    "    print(f'\\n{name} Samples')\n",
    "    display(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "DATA_DIR = '/kaggle/input/home-credit-default-risk/'\n",
    "ds_names = (\"bureau\",\"bureau_balance\",\"credit_card_balance\",\"installments_payments\",\n",
    "            \"previous_application\",\"POS_CASH_balance\")\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    datasets[ds_name] = load_data(os.path.join(DATA_DIR, f'{ds_name}.csv'), ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of values in the target variable\n",
    "temp = train_df[\"TARGET\"].value_counts()\n",
    "df = pd.DataFrame({'labels': temp.index,\n",
    "                   'values': temp.values\n",
    "                  })\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.title('Target')\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x = 'labels', y=\"values\", data=df)\n",
    "locs, labels = plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots checked for numerical properties\n",
    "train_df_num.remove('TARGET')\n",
    "\n",
    "fig, ax = plt.subplots(10, 5, figsize=(15, 15))  \n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, col in enumerate(train_df_num[:50]):\n",
    "    sns.kdeplot(train_df[col], ax=ax[i], color='r')\n",
    "    sns.kdeplot(test_df[col], ax=ax[i], color='g')    \n",
    "    ax[i].set_title(f'{col}')\n",
    "    ax[i].set_xlabel(None)    \n",
    "    \n",
    "for j in range(len(train_df_num[:50]), len(ax)):\n",
    "    ax[j].axis('off')\n",
    "\n",
    "fig.suptitle('Numerical Feature Distributions\\n', fontsize=24, fontweight='bold')\n",
    "fig.legend(['Train', 'Test'])\n",
    "plt.tight_layout(h_pad=0.1, w_pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 6, figsize=(15, 15))  \n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, col in enumerate(train_df_num[50:107]):\n",
    "    sns.kdeplot(train_df[col], ax=ax[i], color='r')\n",
    "    sns.kdeplot(test_df[col], ax=ax[i], color='g')    \n",
    "    ax[i].set_title(f'{col}')\n",
    "    ax[i].set_xlabel(None)    \n",
    "    \n",
    "for j in range(len(train_df_num[50:107]), len(ax)):\n",
    "    ax[j].axis('off')\n",
    "\n",
    "fig.suptitle('Numerical Feature Distributions\\n', fontsize=24, fontweight='bold')\n",
    "fig.legend(['Train', 'Test'])\n",
    "plt.tight_layout(h_pad=0.1, w_pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(20,20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(train_df.select_dtypes(include='object').columns):\n",
    "    sns.countplot(x=col, data=train_df, ax=axes[i], linewidth=1.5,orient=\"h\")\n",
    "    axes[i].set_title(f\"{col} Distribution\", fontsize=10)  \n",
    "\n",
    "    axes[i].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "fig.suptitle(\"Categorical Feature Distributions\", fontsize=20, fontweight='bold')\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Distribution of Applicant's Family Members\", fontweight='bold', fontsize=16)\n",
    "sns.countplot(x='CNT_FAM_MEMBERS', hue='TARGET', data=train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.title(\"Gender borrower\", fontweight = 'bold', fontsize = 16)\n",
    "sns.countplot(x='CODE_GENDER',data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "sns.countplot(x='OCCUPATION_TYPE',hue='TARGET',data=train_df,)\n",
    "plt.xticks(rotation=70)\n",
    "plt.xlabel(\"Occupation Type\")\n",
    "plt.title('Which professions are better customers?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "fig = plt.figure(figsize=[32,50])\n",
    "fig.suptitle('BOXPLOT OF ALL COLUMNS', fontsize=18, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.97);\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4);\n",
    "for i ,col in enumerate(train_df_num[:50]):\n",
    "    ax = fig.add_subplot(14,5, i+1);\n",
    "    ax = sns.boxplot(data = train_df, x=col ,palette=\"husl\");\n",
    "    ax.set_title(f'{col}')\n",
    "    ax.set_xlabel(f'{col}')\n",
    "    ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "fig = plt.figure(figsize=[32,50])\n",
    "fig.suptitle('BOXPLOT OF ALL COLUMNS', fontsize=18, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.97);\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4);\n",
    "for i ,col in enumerate(train_df_num[50:107]):\n",
    "    ax = fig.add_subplot(14,5, i+1);\n",
    "    ax = sns.boxplot(data = train_df, x=col ,palette=\"husl\");\n",
    "    ax.set_title(f'{col}')\n",
    "    ax.set_xlabel(f'{col}')\n",
    "    ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_summary(data):\n",
    "   \n",
    "    missing_values_count = data.isnull().sum()\n",
    "    missing_values_percentage = 100 * missing_values_count / len(data)\n",
    "\n",
    "    \n",
    "    missing_values_summary = pd.DataFrame({\n",
    "        'Missing Data': missing_values_count,\n",
    "        'Missing Data Percentage': missing_values_percentage\n",
    "    })\n",
    "\n",
    "\n",
    "    missing_values_summary = missing_values_summary[missing_values_summary['Missing Data'] > 0]\n",
    "\n",
    "    missing_values_summary = missing_values_summary.sort_values(by='Missing Data Percentage', ascending=False)\n",
    "\n",
    "    return missing_values_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_values_summary(train_df).head(10))\n",
    "display(missing_values_summary(train_df).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['CALC_INCOME_PER_PERSON'] = train_df['AMT_INCOME_TOTAL'] / train_df['CNT_FAM_MEMBERS']\n",
    "test_df['CALC_INCOME_PER_PERSON'] = train_df['AMT_INCOME_TOTAL'] / train_df['CNT_FAM_MEMBERS']\n",
    "\n",
    "train_df['CALC_PERC_DAYS_EMPLOYED'] = train_df['DAYS_EMPLOYED'] / train_df['DAYS_BIRTH']\n",
    "test_df['CALC_PERC_DAYS_EMPLOYED'] = test_df['DAYS_EMPLOYED'] / test_df['DAYS_BIRTH']\n",
    "\n",
    "train_df['CALC_PERC_INCOME_CREDIT'] = train_df['AMT_INCOME_TOTAL'] /train_df['AMT_CREDIT']\n",
    "test_df['CALC_PERC_INCOME_CREDIT'] = test_df['AMT_INCOME_TOTAL'] /test_df['AMT_CREDIT']\n",
    "\n",
    "\n",
    "train_df['ANNUITY_INCOME_PERCENT'] = train_df['AMT_ANNUITY'] / train_df['AMT_INCOME_TOTAL']\n",
    "test_df['ANNUITY_INCOME_PERCENT'] = test_df['AMT_ANNUITY'] / test_df['AMT_INCOME_TOTAL']\n",
    "\n",
    "\n",
    "train_df['CREDIT_TERM'] = train_df['AMT_ANNUITY'] / train_df['AMT_CREDIT']\n",
    "test_df['CREDIT_TERM'] = test_df['AMT_ANNUITY'] / test_df['AMT_CREDIT']\n",
    "\n",
    "\n",
    "# Removing unnecessary features\n",
    "train_df.drop(['FLAG_MOBIL','FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12'],axis=1,inplace=True)\n",
    "test_df.drop(['FLAG_MOBIL','FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('TARGET', axis=1)\n",
    "y = train_df['TARGET']\n",
    "X_test = test_df\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "X_final = preprocessor.fit_transform(X)\n",
    "processed_features = numerical_features.tolist() + preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features).tolist()\n",
    "X_final = pd.DataFrame(X_final, columns=processed_features)\n",
    "\n",
    "X_test_final = preprocessor.fit_transform(X_test)\n",
    "processed_features = numerical_features.tolist() + preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features).tolist()\n",
    "X_test_final = pd.DataFrame(X_test_final, columns=processed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data in the train set that is not tested is removed\n",
    "X_final = X_final.drop(columns = ['CODE_GENDER_XNA', 'NAME_FAMILY_STATUS_Unknown', 'NAME_INCOME_TYPE_Maternity leave'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.concat([X_final, X_test_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_aggregate(df, group_col):\n",
    "    \n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "    \n",
    "   \n",
    "    numeric_imputer = SimpleImputer(strategy='mean')\n",
    "    df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    \n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    encoded_categorical = onehot_encoder.fit_transform(df[categorical_cols])\n",
    "    encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "    \n",
    "    df = pd.concat([df[numeric_cols], encoded_categorical_df], axis=1)\n",
    "\n",
    "   \n",
    "    aggregation_funcs = {\n",
    "        col: ['median', 'mean', 'std', 'min', 'max'] for col in df.columns if col != group_col\n",
    "    }\n",
    "    \n",
    "    aggregated_df = df.groupby(group_col).agg(aggregation_funcs)\n",
    "    \n",
    "    # Flatten multi-level column names\n",
    "    aggregated_df.columns = ['_'.join(col).strip() for col in aggregated_df.columns.values]\n",
    "    \n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_values_summary(bureau_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_df_final =preprocess_and_aggregate(bureau_df, 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = train_test_df.merge(right=bureau_df_final.reset_index(), how='left', on='SK_ID_CURR')\n",
    "train_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_values_summary(pos_cash_balance_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_df_final =preprocess_and_aggregate(pos_cash_balance_df, 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = train_test_df.merge(right=pos_cash_balance_df_final.reset_index(), how='left', on='SK_ID_CURR')\n",
    "train_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_values_summary(credit_card_balance_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = credit_card_balance_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = credit_card_balance_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "credit_card_balance_df[numeric_cols] = numeric_imputer.fit_transform(credit_card_balance_df[numeric_cols])\n",
    "scaler = StandardScaler()\n",
    "credit_card_balance_df[numeric_cols] = scaler.fit_transform(credit_card_balance_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prevs = credit_card_balance_df[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "credit_card_balance_df['SK_ID_PREV'] = credit_card_balance_df['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "\n",
    "\n",
    "avg_cc_bal = credit_card_balance_df.groupby('SK_ID_CURR')[numeric_cols].mean()\n",
    "\n",
    "\n",
    "avg_cc_bal.columns = ['cc_bal_' + f_ for f_ in avg_cc_bal.columns]\n",
    "avg_cc_bal = avg_cc_bal.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = train_test_df.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "train_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_values_summary(installments_payments_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = installments_payments_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = installments_payments_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "installments_payments_df[numeric_cols] = numeric_imputer.fit_transform(installments_payments_df[numeric_cols])\n",
    "scaler = StandardScaler()\n",
    "installments_payments_df[numeric_cols] = scaler.fit_transform(installments_payments_df[numeric_cols])\n",
    "\n",
    "\n",
    "installments_payments_df_final = installments_payments_df[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = train_test_df.merge(right=installments_payments_df_final.reset_index(), how='left', on='SK_ID_CURR')\n",
    "train_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_values_summary(previous_application_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application_df = previous_application_df.drop(['RATE_INTEREST_PRIVILEGED','RATE_INTEREST_PRIMARY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = previous_application_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = previous_application_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "previous_application_df[numeric_cols] = numeric_imputer.fit_transform(previous_application_df[numeric_cols])\n",
    "scaler = StandardScaler()\n",
    "previous_application_df[numeric_cols] = scaler.fit_transform(previous_application_df[numeric_cols])\n",
    "\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "previous_application_df[categorical_cols] = categorical_imputer.fit_transform(previous_application_df[categorical_cols])\n",
    "\n",
    "    \n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoded_categorical = onehot_encoder.fit_transform(previous_application_df[categorical_cols])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "    \n",
    "previous_application_final = pd.concat([previous_application_df[numeric_cols], encoded_categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_apps_count = previous_application_final[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "previous_application_final['SK_ID_PREV'] = previous_application_final['SK_ID_CURR'].map(prev_apps_count['SK_ID_PREV'])\n",
    "\n",
    "## Average values for all other features in previous applications\n",
    "prev_apps_avg = previous_application_final.groupby('SK_ID_CURR').mean()\n",
    "prev_apps_avg.columns = ['p_' + col for col in prev_apps_avg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = train_test_df.merge(right=prev_apps_avg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "train_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_test_df.iloc[:len(train_df),:]\n",
    "test=train_test_df.iloc[len(train_df):,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.01)\n",
    "sel.fit(X_final) \n",
    "mask = sel.get_support()\n",
    "print(len(mask))\n",
    "selected_columns = X_final.columns[mask]\n",
    "X_final_selected = X_final[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# ridge_params = {'alpha': 1.0}\n",
    "# ridge = RidgeClassifier(**ridge_params)\n",
    "\n",
    "\n",
    "catboost_params = {'iterations': 100,\n",
    "                   'depth': 6,\n",
    "                   'scale_pos_weight': 5,\n",
    "                   'bootstrap_type': 'Bernoulli',\n",
    "                   'learning_rate': 0.1,\n",
    "                   'eval_metric':'AUC',\n",
    "                   'od_type': 'Iter',\n",
    "                   'random_strength': 1,\n",
    "                   'early_stopping_rounds': 50,\n",
    "                   'subsample': 0.8,\n",
    "                   'verbose': 0}\n",
    "\n",
    "catboost = CatBoostClassifier(**catboost_params)\n",
    "\n",
    "# ridge_scores = cross_val_score(ridge, X_processed, y, cv=skf, scoring='accuracy')\n",
    "# print(\"RidgeClassifier Accuracy: \", np.mean(ridge_scores))\n",
    "\n",
    "\n",
    "catboost_scores = cross_val_score(catboost, X_final_selected, y, cv=skf, scoring='accuracy')\n",
    "print(\"CatBoostClassifier Accuracy: \", np.mean(catboost_scores))\n",
    "\n",
    "# ridge_scores_roc = cross_val_score(ridge, X_processed, y, cv=skf, scoring='roc_auc')\n",
    "catboost_scores_roc = cross_val_score(catboost, X_final_selected, y, cv=skf, scoring='roc_auc')\n",
    "\n",
    "\n",
    "# print(\"RidgeClassifier ROC: \", np.mean(ridge_scores_roc))\n",
    "print(\"CatBoostClassifier ROC: \", np.mean(catboost_scores_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y, columns = ['TARGET'])\n",
    "X_final_selected['TARGET'] = y_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [str(col) for col in X_final_selected.columns if col != \"TARGET\"]\n",
    "\n",
    "sample_df = X_final_selected.sample(frac=0.1)\n",
    "sample_df.sort_values(\"TARGET\", inplace=True) \n",
    "\n",
    "# define the validation scheme\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=sample_df, target=\"TARGET\", features = features)\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, model = catboost, scoring=\"roc_auc\")\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(importance_df, figsize=(12, 20))\n",
    "plt.gca().yaxis.set_ticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the best features for our model\n",
    "# X_final = X_final.drop('TARGET', axis = 1)\n",
    "neg_feature = importance_df[importance_df[\"importance_mean\"] < 0][\"feature\"].tolist()\n",
    "print(len(neg_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_new = X_final_selected.drop(columns = neg_feature,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_new = X_final_selected.drop(columns = 'TARGET',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_final_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Optuna workspace\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 2, 10),\n",
    "         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.2),\n",
    "        'scale_pos_weight': trial.suggest_loguniform('scale_pos_weight', 1, 10),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 1e-3, 10),\n",
    "        'bootstrap_type': 'Bernoulli',\n",
    "        'eval_metric': 'AUC',\n",
    "        'od_type': 'Iter',\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**param)\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "    auc = roc_auc_score(y_valid, y_pred)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = { 'iterations': 817,\n",
    "               'depth': 5, \n",
    "               'l2_leaf_reg': 1.6188174269842595, \n",
    "               'learning_rate': 0.07525332174980123,\n",
    "               'scale_pos_weight': 2.2276843669235515,\n",
    "               'subsample': 0.8572821079427205, \n",
    "               'random_strength': 0.004554358987876041,\n",
    "               'bootstrap_type': 'Bernoulli',\n",
    "               'eval_metric': 'AUC',\n",
    "               'od_type': 'Iter',\n",
    "               'early_stopping_rounds': 50,\n",
    "               'verbose': 0,\n",
    "    }\n",
    "best_model = CatBoostClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "y_pred = best_model.predict_proba(X_valid)[:, 1]\n",
    "final_roc = roc_auc_score(y_valid, y_pred)\n",
    "print(\"ROC AUC score: \", final_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final_new = X_test_final[X_final_new.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_final_new.shape)\n",
    "print(X_test_final_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = CatBoostClassifier(**best_params,verbose = 0)\n",
    "# best_model.fit(X_final_new, y)\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_final_new)\n",
    "\n",
    "# interpret SHAP values\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_final_new, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_final_new.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the clients\n",
    "# Client 1: Model prediction is correct (True Positive or True Negative)\n",
    "correct_indices = np.where((y_valid == (y_pred > 0.5)))[0]\n",
    "client1_index = correct_indices[0]  # Change the index as needed\n",
    "\n",
    "# Client 2: Model prediction is wrong (False Positive or False Negative)\n",
    "incorrect_indices = np.where((y_valid != (y_pred > 0.5)))[0]\n",
    "client2_index = incorrect_indices[0]  # Change the index as needed\n",
    "\n",
    "# Client 3: A client from the test set\n",
    "client3_index = 0  # Change the index as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for training and validation sets\n",
    "shap_values_train = explainer.shap_values(X_train)\n",
    "shap_values_valid = explainer.shap_values(X_valid)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values_test = explainer.shap_values(X_test_final_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JavaScript visualization code\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP force plot for client 1\n",
    "shap.force_plot(explainer.expected_value, shap_values_valid[client1_index], X_valid.iloc[client1_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP force plot for client 2\n",
    "shap.force_plot(explainer.expected_value, shap_values_valid[client2_index], X_valid.iloc[client2_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP force plot for client 3 (from test set)\n",
    "shap.force_plot(explainer.expected_value, shap_values_test[client3_index], X_test_final_new.iloc[client3_index])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 860599,
     "sourceId": 9120,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
